# ionchannel
Example code for University of Liverpool Ion Switching machine learning competition hosted at Kaggle. You'll need to download the dataset from the Kaggle competition page:

https://www.kaggle.com/c/liverpool-ion-switching

This model file represents my work on this project, where I have made late submissions. While the model implementations are stable and concisely implemented in the TensorFlow r2.3 keras API, the dataset preprocessing functionality is a work in progress. The key challenge of the ionchannel switching competition is in processing the dataset to clean the signal of extensive noise and corruption. There are extensive comments and exchange of ideas and hypotheses on the project
discussion list:

https://www.kaggle.com/c/liverpool-ion-switching/discussion

It has been quite a learning experience to see all the ideas and approaches competing teams implemented to try to understand and restore the signal to its natural structure. Its a real testament to the power of open source collaboration in the Artificial Intelligence field. In my code, one should focus on the dataset preprocessing, because this aspect of the implementation limits the generalization of my model. One could also perform a grid search across the window size, 1D Conv padding, and 1D Conv stride parameters, once the data preprocessing issues are resolved.

The model is an implementation of a deep 1D Conv residual network with up to 10 residual blocks implemented. Each residual block is composed by a Conv1D layer followed by a batch normalization layer followed by a ReLU activation layer followed by a Conv1D layer followed by a batch normalization layer followed by an addition layer summing the Conv1D output with the skip connection from the residual block input. I've implemented 5 residual blocks followed by a GlobalMaxPool1D layer followed by a Dense layer followed by an ReLU activation layer followed by an 11 class multiclass softmax layer. The objective function implements Categorical Cross-entropy. Stochastic gradient descent is implemented using the Nadam (Adam with Nesterov momentum) optimizer.

The custom "class TrainingMgmt_CB(tf.keras.callbacks.Callback)" callback manages the training process. This callback supports a configurable early stopping policy, SIGTERM signal handling to terminate the training process at the end of the current epoch, and management of checkpointing the model weights depending on the objective loss and the validation split accuracy. The SIGTERM signal only stops the training at the conclusion of the current epoch. The process then moves onto inference on the test data. I have intent to implement a custom learning rate management policy in this callback in the future. Currently I used the keras standard callbacks for queueing training logs to TensorBoard and learning rate schedule policy. The learning rate schedule policy is static and a clear area that can be dramatically improved with an adaptive learning rate based on the history of the learning process.

The implementation permits easy experimentation of model architecture (e.g., just comment out some of the layers) and layer hyper parameters such as number of filters for each Conv1D layer and the regularization weights, batch size, learning rate schemes, early stopping policy feature window size, etc. The model trained very efficiently up to about 95% accuracy on the training set and the 0.2 validation split. It just doesn't generalize well to the highly corrupted test data set. I've begun to focus on the dataset noise, and this appears to have impacted the training algorithm behaviors. Too early to understand that at this time.

The get_drift_signal function generates one half of the sinussoidal wave to remove the amplitude 5 sign wave drift from the data sets.

The IonChannelData class preprocesses the data set. Method preprocess_50Hz_noise removes the 50 Hz line noise from the data set. Method channel_alignments is a work in progress. It prints out metrics describing the data set statistics. And also implements a channel alignment scheme for the 10 500000 point sequences that comprise the training data set. This is rather easy to do, because we have the ground truth target values from which we map the alignment intervals. Then I normalize the signal for zero mean and scale the signal to 1.0. The primary issue is there are no ground truth values for the test data set. And so one must develop a scheme to align the test data set to be consistent with the training data set. This is the central issue affecting the generalization of the model once trained. Method remove_signal drift calls the get_drift_signal function to then remove the drift from the training and test dataset. Method preprocess_data manages this entire process described above. Finally the dataset is processed to create a window, currently 15 points wide, with the current point centered in the window for odd window sizes. This is clearly an important parameter that works with the 1D Convolution layers, with the padding parameter (valid, causal, or same) and the stride parameters coupled with the window size likely playing a first order role in the model performance, once the data set alignment issue is resolved.

I'm out of time and likely will not invest more time with this project. It is a fun problem to explore.
